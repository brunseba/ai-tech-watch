
# Which mecanisme de encryption, d'authentication, d'habiliation utiliser in des process AI

Pour des process IA sensitives, les m√©canismes de encryption, d'authentication and d'habilitation must suivre une logique Zero Trust : tout flow is chiffr√©, toute entit√© (humain or agent) is authentifi√©e fortement, and chaque acc√®s is limit√© au strict n√©cessaire.[^1][^2][^3]

## Architecture Zero Trust for l'IA

```mermaid
flowchart TB
    subgraph Users["üë• Utilisateurs"]
        U1[UI/Portails]
        U2[IDE/Dev Tools]
    end
    
    subgraph Auth["üîê Authentication"]
        A1[SSO/OIDC]
        A2[MFA obligatoire]
        A3[IdP Entreprise]
    end
    
    subgraph Transit["üîí Encryption Transit"]
        T1[TLS 1.3]
        T2[mTLS Service Mesh]
        T3[Certificats PKI]
    end
    
    subgraph AI["ü§ñ Syst√®me IA"]
        AI1[AI Agents]
        AI2[LLM Runtime]
        AI3[Vector DB]
    end
    
    subgraph Secrets["üîë Gestion Secrets"]
        S1[Vault/KMS]
        S2[Rotation auto]
        S3[HSM]
    end
    
    subgraph AuthZ["‚úÖ Authorization"]
        Z1[RBAC/ABAC]
        Z2[Policy Engine OPA]
        Z3[Least Privilege]
    end
    
    subgraph AtRest["üíæ Encryption Repos"]
        R1[Disque/Volume]
        R2[Object Storage]
        R3[Models chiffr√©s]
    end
    
    subgraph Monitor["üìä Monitoring"]
        M1[SIEM]
        M2[Audit Logs]
        M3[Anomaly Detection]
    end
    
    Users --> Auth
    Auth --> Transit
    Transit --> AI
    AI --> Secrets
    AI --> AuthZ
    AI --> AtRest
    AI --> Monitor
    Secrets --> Transit
    AuthZ --> Monitor
    
    style Users fill:#e3f2fd,stroke:#1e88e5
    style Auth fill:#fff3e0,stroke:#fb8c00
    style Transit fill:#e8f5e9,stroke:#43a047
    style AI fill:#f3e5f5,stroke:#8e24aa
    style Secrets fill:#ffebee,stroke:#e53935
    style AuthZ fill:#c8e6c9,stroke:#2e7d32
    style AtRest fill:#ffe0b2,stroke:#ef6c00
    style Monitor fill:#b3e5fc,stroke:#0277bd
```

## Encryption √† privil√©gier

- En transit : TLS 1.2+ (id√©alement 1.3) partout between clients, API IA, brokers, stores de features and bases de data, with v√©rification stricte des certificats and d√©sactivation des suites faibles.[^4][^5][^1]
- Au repos : encryption disque/volume c√¥t√© bases, object storage, files de messages, and storage de models, with gestion centralis√©e des cl√©s (KMS, HSM or Vault) and rotation r√©guli√®re.[^6][^1][^4]
- Data tr√®s sensitives : combiner encryption with tokenisation or masquage dynamique des PII in les inputs aux models, and logs syst√©matiquement nettoy√©s des data brutes.[^7][^4][^6]


## Authentication des humains

- Utilisateurs finaux (UI, portails, IDE, outils RAG) : SSO (OIDC/SAML) connect√© √† l‚ÄôIdP d‚Äôentreprise, MFA obligatoire for les r√¥les sensitives (ops, data, security, administrateurs de models).[^2][^8][^3]
- Acc√®s aux consoles d‚Äôadmin IA (MLOps, orchestrateurs, vector DB) : authentication forte (MFA, FIDO2/Passkeys or certificats) and interdiction des comptes partag√©s.[^9][^10][^2]


## Authentication des services and agents IA

- Entre microservices, pipelines, agents and backends :
    - Utiliser des identit√©s de workload standardis√©es (SPIFFE/SVID, JWT sign√©s par une PKI internal, or OAuth2 client credentials) plut√¥t que des secrets statiques.[^11][^8][^12]
    - Pr√©f√©rer des credentials √©ph√©m√®res (tokens courts, rotation automatique, session‚Äëbased) and storage uniquement in des coffres chiffr√©s (Vault, KMS, Secret Manager), never in le code or les images.[^8][^13][^11]
- Pour les appels vers des API LLM externals :
    - Isolation des cl√©s API par environnement and par application, rotation r√©guli√®re, and filtrage network sortant for limiter les destinations.[^13][^14][^1]


## Habilitation / authorization

- Mod√®le d‚Äôacc√®s : RBAC or ABAC (attributs r√¥le, √©quipe, classification des data, contexte) combin√© au principe de moindre privil√®ge for les utilisateurs and les agents IA.[^15][^16][^8]
- Data for RAG / features :
    - Le filtrage des documents must se faire c√¥t√© backend fiable, pas par le mod√®le lui‚Äëm√™me (le LLM ne ‚Äúd√©cide‚Äù pas qui a le droit de voir quoi).[^16][^10]
    - Appliquer des filtres d‚Äôauthorizations on les requ√™tes au vectordb or au data store (ex. scope utilisateur, attributs d‚Äôorganisation, labels de sensibilit√©).[^16][^4]
- Agents IA :
    - Identit√© propre par agent, scopes d‚ÄôAPI stricts, access tokens limit√©s in le temps and in le p√©rim√®tre, journaux d‚Äôactions complets for audit.[^17][^11][^8]


## Controls compl√©mentaires sp√©cifiques IA

- Zero Trust IA / LLM :
    - V√©rification syst√©matique de l‚Äôidentit√© √† chaque requ√™te, control dynamique according to la sensibilit√© du prompt and des data, monitoring en temps r√©el for d√©tecter prompt injections and comportements anormaux.[^18][^12][^2]
- Protection des pipelines :
    - Data minimization, DLP/anonymisation en amont du training, signatures or checksums des datasets for d√©tecter data poisoning, and control d‚Äôacc√®s strict au repo de models.[^19][^4][^6]

En pratique, for une stack moderne : TLS 1.3 partout, KMS/Vault for les cl√©s, SSO OIDC + MFA for les humains, SPIFFE/OAuth2 for les workloads, RBAC/ABAC c√¥t√© data and vector DB, tokens courts for agents, and un SIEM branch√© on les logs d‚ÄôAPI IA and de pipelines.[^5][^1][^11][^16]
<span style="display:none">[^20]</span>

<div align="center">‚ÅÇ</div>

[^1]: https://www.sysdig.com/learn-cloud-native/top-8-ai-security-best-practices

[^2]: https://blog.dreamfactory.com/zero-trust-for-llms-applying-security-principles-to-ai-systems

[^3]: https://www.checkpoint.com/fr/cyber-hub/cyber-security/what-is-ai-security/what-is-zero-trust-ai-access-ztai/

[^4]: https://dacodes.com/blog/safeguarding-sensitive-data-in-ai-pipelines

[^5]: https://learn.microsoft.com/en-us/azure/cloud-adoption-framework/scenarios/ai/infrastructure/security

[^6]: https://magedata.ai/whitepaper/securing-sensitive-data-in-ml-pipelines/

[^7]: https://www.sciencedirect.com/science/article/pii/S0167404823005151

[^8]: https://prefactor.tech/blog/5-best-practices-for-ai-agent-access-control

[^9]: https://blog.gitguardian.com/authentication-and-authorization/

[^10]: https://www.refontelearning.com/blog/securing-machine-learning-pipelines-best-practices-for-ai-security

[^11]: https://aembit.io/blog/how-to-secure-non-human-identities-for-ai-workloads/

[^12]: https://xage.com/unified-zero-trust-for-llms-and-ai-agents/

[^13]: https://cloudsecurityalliance.org/blog/2025/09/09/api-security-in-the-ai-era

[^14]: https://www.aikido.dev/blog/cloud-security-best-practices

[^15]: https://www.vanta.com/resources/ai-security-best-practices

[^16]: https://aws.amazon.com/blogs/security/implement-effective-data-authorization-mechanisms-to-secure-your-data-used-in-generative-ai-applications/

[^17]: https://arxiv.org/abs/2510.25819

[^18]: https://www.blackfog.com/zero-trust-approach-llm-prompt-injection-attacks/

[^19]: https://www.dsstream.com/post/security-for-mlops-how-to-safeguard-data-models-and-pipelines-against-modern-ai-threats

[^20]: https://www.aigl.blog/design-principles-for-llm-based-systems-with-zero-trust/

